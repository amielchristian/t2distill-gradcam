{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import keras as keras\n",
    "from keras import layers\n",
    "from keras import ops\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "from vit_keras import vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (512, 512)\n",
    "batch_size = 2\n",
    "accumulation_steps = 16 // batch_size # this simulates a batch size of batch_size*accumulation_steps = 16\n",
    "input_shape = image_size + (3,)\n",
    "learning_rate = 2e-4\n",
    "epochs = 25\n",
    "alpha = 0.75\n",
    "beta = 0.1\n",
    "temperature = 3.0\n",
    "spatial_alignment_layers = 2\n",
    "seed = 1337"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28101 validated image filenames belonging to 5 classes.\n",
      "Found 7025 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def load_data(image_size, batch_size):\n",
    "    data_dir = 'data/train'\n",
    "\n",
    "    labels_df = pd.read_csv('data/train_labels.csv')\n",
    "    labels_df['image'] = labels_df['image'].apply(lambda x: f\"{data_dir}/{x}.jpeg\")\n",
    "    labels_df['level'] = labels_df['level'].astype(str)\n",
    "\n",
    "    train_data_augmentation = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=360,  # Random rotation up to 90 degrees\n",
    "        width_shift_range=0.2,  # Random horizontal shift\n",
    "        height_shift_range=0.2,  # Random vertical shift\n",
    "        zoom_range=[0.87, 1.15],\n",
    "        brightness_range=[0.8, 1.2],\n",
    "        horizontal_flip=True,  # Random horizontal flip\n",
    "        vertical_flip=True,  # Random vertical flip\n",
    "        validation_split=0.2,\n",
    "        fill_mode='constant'\n",
    "    )\n",
    "\n",
    "    # Define data augmentation for validation (only rescaling)\n",
    "    val_data_augmentation = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        validation_split=0.2,\n",
    "    )\n",
    "\n",
    "    # Load training dataset with augmentation\n",
    "    train_ds = train_data_augmentation.flow_from_dataframe(\n",
    "        dataframe=labels_df,\n",
    "        x_col='image',\n",
    "        y_col='level',\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        subset='training',\n",
    "        seed=seed,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    # Load validation dataset without augmentation\n",
    "    val_ds = val_data_augmentation.flow_from_dataframe(\n",
    "        dataframe=labels_df,\n",
    "        x_col='image',\n",
    "        y_col='level',\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        subset='validation',\n",
    "        seed=seed,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_ds, val_ds\n",
    "\n",
    "# Load the data\n",
    "train_ds, val_ds = load_data(image_size, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1749171116.741793   14605 cuda_executor.cc:1228] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1749171116.742640   14605 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/faustomorales/vit-keras/releases/download/dl/ViT-B_16_imagenet21k+imagenet2012.npz\n",
      "\u001b[1m347502902/347502902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amiel/Projects/t2distill-gradcam/vit_keras/utils.py:81: UserWarning: Resizing position embeddings from 24, 24 to 32, 32\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = 'data/FinalModels/teacher_resnet/model.weights.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m x = tf.keras.layers.Dense(\u001b[32m5\u001b[39m)(x)\n\u001b[32m     23\u001b[39m teacher = Model(teacher.input, x)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43mteacher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m teacher.trainable = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/t2distill-gradcam/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/t2distill-gradcam/.venv/lib/python3.12/site-packages/h5py/_hl/files.py:564\u001b[39m, in \u001b[36mFile.__init__\u001b[39m\u001b[34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[39m\n\u001b[32m    555\u001b[39m     fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[32m    556\u001b[39m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[32m    557\u001b[39m                      alignment_threshold=alignment_threshold,\n\u001b[32m    558\u001b[39m                      alignment_interval=alignment_interval,\n\u001b[32m    559\u001b[39m                      meta_block_size=meta_block_size,\n\u001b[32m    560\u001b[39m                      **kwds)\n\u001b[32m    561\u001b[39m     fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[32m    562\u001b[39m                      fs_persist=fs_persist, fs_threshold=fs_threshold,\n\u001b[32m    563\u001b[39m                      fs_page_size=fs_page_size)\n\u001b[32m--> \u001b[39m\u001b[32m564\u001b[39m     fid = \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    567\u001b[39m     \u001b[38;5;28mself\u001b[39m._libver = libver\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/t2distill-gradcam/.venv/lib/python3.12/site-packages/h5py/_hl/files.py:238\u001b[39m, in \u001b[36mmake_fid\u001b[39m\u001b[34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[39m\n\u001b[32m    236\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[32m    237\u001b[39m         flags |= h5f.ACC_SWMR_READ\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m     fid = \u001b[43mh5f\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mode == \u001b[33m'\u001b[39m\u001b[33mr+\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    240\u001b[39m     fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:54\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:55\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/h5f.pyx:102\u001b[39m, in \u001b[36mh5py.h5f.open\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'data/FinalModels/teacher_resnet/model.weights.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "student = vit.vit_b16(\n",
    "    weights='imagenet21k+imagenet2012',\n",
    "    image_size = 512,\n",
    "    pretrained=True,\n",
    "    pretrained_top=False,\n",
    "    classes=5,\n",
    ")\n",
    "\n",
    "data_dir = 'data'\n",
    "model_folder= \"FinalModels/teacher_resnet\"\n",
    "config_json = f'{data_dir}/{model_folder}/config.json'\n",
    "model_path = f'{data_dir}/{model_folder}/model.weights.h5'\n",
    "teacher = tf.keras.applications.ResNet50V2(\n",
    "    include_top=False,\n",
    "    weights=None,\n",
    "    input_shape=(512, 512, 3),\n",
    "    classes=5\n",
    ")\n",
    "x = teacher.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(5)(x)\n",
    "\n",
    "teacher = Model(teacher.input, x)\n",
    "teacher.load_weights(model_path)\n",
    "teacher.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from knowledge_distillation import Distiller\n",
    "\n",
    "teacher.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "total_steps = epochs * 14051\n",
    "\n",
    "cosine_decay_fn = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=learning_rate, decay_steps=total_steps, alpha=2e-6\n",
    ")\n",
    "distiller = Distiller(student=student, teacher=teacher)\n",
    "distiller.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=cosine_decay_fn, gradient_accumulation_steps=accumulation_steps),\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "    ],\n",
    "    student_loss_fn=keras.losses.CategoricalCrossentropy(),\n",
    "    logit_loss_fn=keras.losses.KLDivergence(),\n",
    "    feature_loss_fn=keras.losses.CosineSimilarity(),\n",
    "    alpha=alpha,\n",
    "    beta=beta,\n",
    "    temperature=temperature,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "from tensorflow.keras.callbacks import Callback, BackupAndRestore\n",
    "\n",
    "# Define model_id and log_dir\n",
    "model_id = \"GAMEKD\"+distiller.name + '_' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = f\"../{model_id}/logs\"\n",
    "os.makedirs(log_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_run_time = None\n",
    "array = []\n",
    "\n",
    "# if training is resumed\n",
    "log_file = f'resume_epoch_logs_{model_id}.json'\n",
    "if os.path.exists(log_file):\n",
    "    with open(log_file, 'r') as f:\n",
    "        array = json.load(f)\n",
    "        print(array)\n",
    "        \n",
    "class FinalEpochLogger(Callback):\n",
    "    def __init__(self, log_file=f'resume_epoch_logs_{model_id}.json'):\n",
    "        super(FinalEpochLogger, self).__init__()\n",
    "        self.log_file = log_file\n",
    "        array = self.load_logs()\n",
    "        self.total_time = self.load_elapsed_time()\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.time_start = datetime.datetime.now()\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        self.update_elapsed_time()\n",
    "        self.save_elapsed_time()\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.update_elapsed_time()\n",
    "        self.time_start = datetime.datetime.now()\n",
    "\n",
    "    def update_elapsed_time(self):\n",
    "        self.time_end = datetime.datetime.now()\n",
    "        elapsed_time = (self.time_end - self.time_start).total_seconds()\n",
    "        self.total_time += elapsed_time\n",
    "\n",
    "    def save_elapsed_time(self):\n",
    "        elapsed_time_file = self.log_file.replace('.json', '_elapsed_time.json')\n",
    "        with open(elapsed_time_file, 'w') as f:\n",
    "            json.dump(self.total_time, f)\n",
    "\n",
    "    def load_elapsed_time(self):\n",
    "        elapsed_time_file = self.log_file.replace('.json', '_elapsed_time.json')\n",
    "        if os.path.exists(elapsed_time_file):\n",
    "            with open(elapsed_time_file, 'r') as f:\n",
    "                return json.load(f)\n",
    "        return 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        array.append(f\"Epoch {epoch+1}: {logs}\\n\")\n",
    "        self.save_logs()\n",
    "\n",
    "    def save_logs(self):\n",
    "        with open(self.log_file, 'w') as f:\n",
    "            json.dump(array, f)\n",
    "\n",
    "    def load_logs(self):\n",
    "        if os.path.exists(self.log_file):\n",
    "            with open(self.log_file, 'r') as f:\n",
    "                return json.load(f)\n",
    "        return []\n",
    "final_epoch_logger = FinalEpochLogger()\n",
    "backup_dir = './backup'\n",
    "backup_callback = BackupAndRestore(backup_dir=backup_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distiller.build(input_shape)\n",
    "distiller.fit(train_ds,\n",
    "              epochs=epochs,\n",
    "              validation_data=val_ds,\n",
    "              # steps_per_epoch=steps_per_epoch,\n",
    "              callbacks=[\n",
    "                tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, mode='max'),\n",
    "                tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1),\n",
    "                final_epoch_logger,\n",
    "                backup_callback\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_runtime = final_epoch_logger.total_time\n",
    "#make total runtime in HH: MM: SS format\n",
    "total_runtime = str(datetime.timedelta(seconds=total_runtime))\n",
    "print(f\"Total runtime: {total_runtime} hours\")\n",
    "print(log_dir)\n",
    "os.makedirs(f\"/mnt/c/Users/Ann Clarisse Salazar/Documents/project/records_kd/{model_id}\", exist_ok=True)\n",
    "distiller.student.save(f'/mnt/c/Users/Ann Clarisse Salazar/Documents/project/records_kd/{model_id}/model_{model_id}.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "note = f\"NOTE: cam_kd, {spatial_alignment_layers} spatial alignment layers, limited set, {beta} beta, use base vit with pretraining, no cams, base KD\"\n",
    "\n",
    "# Create a StringIO object to capture the output\n",
    "output_capture = io.StringIO()\n",
    "\n",
    "# Redirect stdout to the StringIO object\n",
    "sys.stdout = output_capture\n",
    "print(note + \"\\n\\n\")\n",
    "\n",
    "# print training info\n",
    "for element in array:\n",
    "    print(element)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# print model info\n",
    "print(\"HYPERPARAMETERS\")\n",
    "print(f\"Model Name: {distiller.name}\")\n",
    "print(f\"Epochs: {epochs}\")\n",
    "print(f\"Batch Size: {batch_size}\")\n",
    "print(f\"Image Size: {image_size}\")\n",
    "print(f\"Learning Rate: {learning_rate}\")\n",
    "print(f\"Alpha: {alpha}\")\n",
    "print(f\"Beta: {beta}\")\n",
    "print(f\"Temperature: {temperature}\")\n",
    "print(f\"Total runtime: {total_runtime}\")\n",
    "print(f\"Tensorflow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {keras.__version__}\")\n",
    "\n",
    "# Reset stdout to its original value\n",
    "sys.stdout = sys.__stdout__\n",
    "\n",
    "# Get the captured output\n",
    "captured_output = output_capture.getvalue()\n",
    "\n",
    "file_path = f'../records_kd/{model_id}/info.txt'\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "\n",
    "# save to info.txt\n",
    "with open(f\"../records_kd/{model_id}/info.txt\", 'w') as file:\n",
    "    file.write(captured_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
